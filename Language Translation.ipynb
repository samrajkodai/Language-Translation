{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320f1da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM,Input,Bidirectional,Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size=64\n",
    "epochs=100\n",
    "latent_dim=256\n",
    "num_samples=10000\n",
    "data_path='./tam.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cadb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_characters=set()\n",
    "target_characters=set()\n",
    "\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.read().split(\"\\n\")\n",
    "\n",
    "for line in lines[: min(num_samples,len(lines)-1)]:\n",
    "    input_text,target_text,_=line.split(\"\\t\")\n",
    "    \n",
    "    target_text='\\t'+target_text+'\\n'\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "            \n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6fbf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I slept.',\n",
       " 'Calm down.',\n",
       " \"I'll walk.\",\n",
       " 'Who is he?',\n",
       " 'Who knows?',\n",
       " 'She smiled.',\n",
       " 'Talk to me!',\n",
       " 'Who is she?',\n",
       " 'Go to sleep.',\n",
       " 'It may rain.',\n",
       " 'She bit him.',\n",
       " 'She hit him.',\n",
       " 'She is kind.',\n",
       " 'She is eight.',\n",
       " 'Where are we?',\n",
       " 'Keep in touch!',\n",
       " 'See you again.',\n",
       " 'Give it to her.',\n",
       " 'I ate too much.',\n",
       " \"I'll see to it.\",\n",
       " \"It's up to you.\",\n",
       " 'Leave it to me.',\n",
       " 'Listen to this!',\n",
       " \"That's the way.\",\n",
       " 'Come and see me.',\n",
       " \"Don't lie to me.\",\n",
       " 'He began to run.',\n",
       " 'He just arrived.',\n",
       " 'He likes to run.',\n",
       " 'How is your dad?',\n",
       " 'I want to sleep.',\n",
       " \"I'm able to run.\",\n",
       " 'Raise your hand.',\n",
       " 'What did he say?',\n",
       " 'When can we eat?',\n",
       " 'Come and help us.',\n",
       " 'He is still here.',\n",
       " 'I have to go now.',\n",
       " 'I know that much.',\n",
       " 'I made a mistake.',\n",
       " 'I walk to school.',\n",
       " \"That's our house.\",\n",
       " 'Those are my CDs.',\n",
       " 'Walk ahead of me.',\n",
       " \"We'll follow you.\",\n",
       " 'Beware of the dog!',\n",
       " 'He came back soon.',\n",
       " 'He has three sons.',\n",
       " 'I know how to ski.',\n",
       " 'I know what to do.',\n",
       " \"I'm kind of happy.\",\n",
       " 'Keep to the right.',\n",
       " 'She began to sing.',\n",
       " 'She decided to go.',\n",
       " 'Do I have to study?',\n",
       " 'He is sure to come.',\n",
       " 'I had to walk home.',\n",
       " 'I have to dress up.',\n",
       " 'I told him to come.',\n",
       " \"I'm short of money.\",\n",
       " 'May I speak to you?',\n",
       " 'She gave it to him.',\n",
       " 'She is kind to him.',\n",
       " 'She sat next to me.',\n",
       " 'Shut up and listen!',\n",
       " 'Tell me what to do.',\n",
       " 'Tom runs very fast.',\n",
       " 'We ran out of food.',\n",
       " 'We started to walk.',\n",
       " 'When does it begin?',\n",
       " 'Are you ready to go?',\n",
       " 'Do you have any gum?',\n",
       " 'Does she play piano?',\n",
       " \"Don't listen to her.\",\n",
       " 'Go and wake Mary up.',\n",
       " 'He seems to know us.',\n",
       " 'I am engaged to her.',\n",
       " 'I have to leave now.',\n",
       " 'I want to go abroad.',\n",
       " \"I'm glad to see you.\",\n",
       " \"I'm proud of my son.\",\n",
       " \"I'm taller than you.\",\n",
       " \"I'm trying to sleep.\",\n",
       " \"It's free of charge.\",\n",
       " \"It's time to get up.\",\n",
       " 'Nobody speaks to me.',\n",
       " 'Roll the ball to me.',\n",
       " 'She boiled the eggs.',\n",
       " 'She danced with him.',\n",
       " 'She gave him a book.',\n",
       " 'She has 2,000 books.',\n",
       " 'This apple is sweet.',\n",
       " 'We swam in the lake.',\n",
       " 'Come home before six.',\n",
       " 'Go and see who it is.',\n",
       " 'I am afraid of bears.',\n",
       " 'I expect him to come.',\n",
       " \"It's a piece of cake.\",\n",
       " 'The boy began to cry.',\n",
       " 'You keep out of this.',\n",
       " 'All of us were silent.',\n",
       " 'Be kind to old people.',\n",
       " 'Beware of pickpockets.',\n",
       " \"Don't drink and drive.\",\n",
       " 'He can read and write.',\n",
       " 'He got a lot of money.',\n",
       " 'He has a lot of money.',\n",
       " 'He is afraid of death.',\n",
       " 'He let go of the rope.',\n",
       " 'I am tired of my work.',\n",
       " 'I got out of the taxi.',\n",
       " 'None of your business.',\n",
       " 'They made fun of Mary.',\n",
       " 'Tom and I are friends.',\n",
       " 'When is your birthday?',\n",
       " 'All of them went there.',\n",
       " 'Can you ride a bicycle?',\n",
       " 'Do you want to be rich?',\n",
       " 'He is afraid of snakes.',\n",
       " 'He is fond of swimming.',\n",
       " 'He went in place of me.',\n",
       " \"He's afraid of the sea.\",\n",
       " \"I'll leave that to you.\",\n",
       " 'It seems she hates you.',\n",
       " 'She got engaged to him.',\n",
       " 'She got married to him.',\n",
       " 'She stood close to him.',\n",
       " \"They're about to leave.\",\n",
       " 'This CD belongs to her.',\n",
       " 'We ran after the thief.',\n",
       " 'What do you plan to do?',\n",
       " 'A square has four sides.',\n",
       " 'Charge it to my account.',\n",
       " 'He asked us to help him.',\n",
       " 'He is known to everyone.',\n",
       " 'He objected to our plan.',\n",
       " 'I just want you to come.',\n",
       " 'I want something to eat.',\n",
       " 'Is he a friend of yours?',\n",
       " 'The news quickly spread.',\n",
       " \"I can't find it anywhere.\",\n",
       " \"I thought you'd be angry.\",\n",
       " 'Please sit here and wait.',\n",
       " 'She went out of the room.',\n",
       " 'Speak slowly and clearly.',\n",
       " 'The sky is full of stars.',\n",
       " 'Come and see me right now.',\n",
       " 'Do you have a lot of pens?',\n",
       " 'Go and sit by your father.',\n",
       " 'He bought a pair of shoes.',\n",
       " 'I live on the bottom floor.',\n",
       " 'I sat between Tom and John.',\n",
       " 'She wore a beautiful dress.',\n",
       " 'When did you come to Japan?',\n",
       " \"Don't tell Tom you're a cop.\",\n",
       " \"Don't think about it. Do it.\",\n",
       " \"Most people think I'm crazy.\",\n",
       " 'I suppose Tom is still alive.',\n",
       " 'She asked him for some money.',\n",
       " 'Tom told me about it himself.',\n",
       " 'Do you know when he will come?',\n",
       " 'He painted a picture of a dog.',\n",
       " 'I arrived ahead of the others.',\n",
       " 'I know every inch of the town.',\n",
       " \"I'm not sharing this with Tom.\",\n",
       " 'She is not afraid of anything.',\n",
       " 'The price of eggs is going up.',\n",
       " 'Tom picked up the soccer ball.',\n",
       " 'What is the price of this cap?',\n",
       " 'Which of them is your brother?',\n",
       " 'He arrived after the bell rang.',\n",
       " 'He was not aware of the danger.',\n",
       " 'My throat hurts when I swallow.',\n",
       " 'The school looks like a prison.',\n",
       " \"I'm not sure how to answer this.\",\n",
       " \"There's no easy way out of here.\",\n",
       " 'Three vicious dogs attacked Tom.',\n",
       " 'Tom was in Australia a year ago.',\n",
       " 'When did the wedding take place?',\n",
       " 'Where do you keep your passport?',\n",
       " \"Because he's sick, he can't come.\",\n",
       " 'Friendship requires mutual trust.',\n",
       " \"He put the ring on Mary's finger.\",\n",
       " 'She glanced through the magazine.',\n",
       " 'Tom has been crying all afternoon.',\n",
       " 'Tom has been in contact with Mary.',\n",
       " 'I want to be a pilot in the future.',\n",
       " 'If Tom ran away, where could he go?',\n",
       " 'I had my pocket picked on the train.',\n",
       " 'He told her something and she smiled.',\n",
       " \"I don't like to go out when it's dark.\",\n",
       " 'When he spoke, everyone became silent.',\n",
       " 'Tom drank with us until after midnight.',\n",
       " 'She has never been in a car driven by him.',\n",
       " 'Tom goes to church with Mary every Sunday.',\n",
       " \"I don't think people use that word anymore.\",\n",
       " 'My younger sister got married in her teens.',\n",
       " 'I wonder why Tom suggested we do that together.',\n",
       " \"Tom says he doesn't think he can do that by himself.\",\n",
       " \"People who live in glass houses shouldn't throw stones.\",\n",
       " \"It's been a long time since I've heard anyone use that word.\",\n",
       " 'If you want your workers to be happy, you need to pay them a decent wage.',\n",
       " \"It's my fault that the cake was burned. I was talking on the phone and didn't notice the time.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e517daf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '0',\n",
       " '2',\n",
       " '?',\n",
       " 'C',\n",
       " 'D',\n",
       " 'அ',\n",
       " 'ஆ',\n",
       " 'இ',\n",
       " 'உ',\n",
       " 'ஊ',\n",
       " 'எ',\n",
       " 'ஏ',\n",
       " 'ஒ',\n",
       " 'ஓ',\n",
       " 'க',\n",
       " 'ங',\n",
       " 'ச',\n",
       " 'ஜ',\n",
       " 'ஞ',\n",
       " 'ட',\n",
       " 'ண',\n",
       " 'த',\n",
       " 'ந',\n",
       " 'ன',\n",
       " 'ப',\n",
       " 'ம',\n",
       " 'ய',\n",
       " 'ர',\n",
       " 'ற',\n",
       " 'ல',\n",
       " 'ள',\n",
       " 'ழ',\n",
       " 'வ',\n",
       " 'ஷ',\n",
       " 'ஸ',\n",
       " 'ா',\n",
       " 'ி',\n",
       " 'ீ',\n",
       " 'ு',\n",
       " 'ூ',\n",
       " 'ெ',\n",
       " 'ே',\n",
       " 'ை',\n",
       " 'ொ',\n",
       " 'ோ',\n",
       " '்'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c33f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters=sorted(list(input_characters))\n",
    "target_characters=sorted(list(target_characters))\n",
    "num_encoder_token=len(input_characters)\n",
    "num_target_token=len(target_characters)\n",
    "max_encoder_length=max([len(text) for text in input_texts])\n",
    "max_decoder_length=max([len(text) for text in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7dc81d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_encoder_length 94\n",
      "max_decoder_length 111\n",
      "unique encoder 53\n",
      "unique decoder 54\n"
     ]
    }
   ],
   "source": [
    "print(\"max_encoder_length\",max_encoder_length)\n",
    "print(\"max_decoder_length\",max_decoder_length)\n",
    "print(\"unique encoder\",num_encoder_token)\n",
    "print(\"unique decoder\",num_target_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a106e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's my fault that the cake was burned. I was talking on the phone and didn't notice the time.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b279b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index=dict([(i,char) for char,i in enumerate(input_characters)])\n",
    "target_token_index=dict([(i,char) for char,i in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d1946d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({' ': 0,\n",
       "  '!': 1,\n",
       "  \"'\": 2,\n",
       "  ',': 3,\n",
       "  '.': 4,\n",
       "  '0': 5,\n",
       "  '2': 6,\n",
       "  '?': 7,\n",
       "  'A': 8,\n",
       "  'B': 9,\n",
       "  'C': 10,\n",
       "  'D': 11,\n",
       "  'F': 12,\n",
       "  'G': 13,\n",
       "  'H': 14,\n",
       "  'I': 15,\n",
       "  'J': 16,\n",
       "  'K': 17,\n",
       "  'L': 18,\n",
       "  'M': 19,\n",
       "  'N': 20,\n",
       "  'P': 21,\n",
       "  'R': 22,\n",
       "  'S': 23,\n",
       "  'T': 24,\n",
       "  'W': 25,\n",
       "  'Y': 26,\n",
       "  'a': 27,\n",
       "  'b': 28,\n",
       "  'c': 29,\n",
       "  'd': 30,\n",
       "  'e': 31,\n",
       "  'f': 32,\n",
       "  'g': 33,\n",
       "  'h': 34,\n",
       "  'i': 35,\n",
       "  'j': 36,\n",
       "  'k': 37,\n",
       "  'l': 38,\n",
       "  'm': 39,\n",
       "  'n': 40,\n",
       "  'o': 41,\n",
       "  'p': 42,\n",
       "  'q': 43,\n",
       "  'r': 44,\n",
       "  's': 45,\n",
       "  't': 46,\n",
       "  'u': 47,\n",
       "  'v': 48,\n",
       "  'w': 49,\n",
       "  'x': 50,\n",
       "  'y': 51,\n",
       "  'z': 52},\n",
       " {'\\t': 0,\n",
       "  '\\n': 1,\n",
       "  ' ': 2,\n",
       "  '!': 3,\n",
       "  '(': 4,\n",
       "  ')': 5,\n",
       "  ',': 6,\n",
       "  '.': 7,\n",
       "  '0': 8,\n",
       "  '2': 9,\n",
       "  '?': 10,\n",
       "  'C': 11,\n",
       "  'D': 12,\n",
       "  'அ': 13,\n",
       "  'ஆ': 14,\n",
       "  'இ': 15,\n",
       "  'உ': 16,\n",
       "  'ஊ': 17,\n",
       "  'எ': 18,\n",
       "  'ஏ': 19,\n",
       "  'ஒ': 20,\n",
       "  'ஓ': 21,\n",
       "  'க': 22,\n",
       "  'ங': 23,\n",
       "  'ச': 24,\n",
       "  'ஜ': 25,\n",
       "  'ஞ': 26,\n",
       "  'ட': 27,\n",
       "  'ண': 28,\n",
       "  'த': 29,\n",
       "  'ந': 30,\n",
       "  'ன': 31,\n",
       "  'ப': 32,\n",
       "  'ம': 33,\n",
       "  'ய': 34,\n",
       "  'ர': 35,\n",
       "  'ற': 36,\n",
       "  'ல': 37,\n",
       "  'ள': 38,\n",
       "  'ழ': 39,\n",
       "  'வ': 40,\n",
       "  'ஷ': 41,\n",
       "  'ஸ': 42,\n",
       "  'ா': 43,\n",
       "  'ி': 44,\n",
       "  'ீ': 45,\n",
       "  'ு': 46,\n",
       "  'ூ': 47,\n",
       "  'ெ': 48,\n",
       "  'ே': 49,\n",
       "  'ை': 50,\n",
       "  'ொ': 51,\n",
       "  'ோ': 52,\n",
       "  '்': 53})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index,target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d3f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data=np.zeros((len(input_texts),max_encoder_length,num_encoder_token),dtype=\"float32\")\n",
    "\n",
    "decoder_input_data=np.zeros((len(target_texts),max_decoder_length,num_target_token),dtype=\"float32\")\n",
    "\n",
    "decoder_target_data=np.zeros((len(input_texts),max_decoder_length,num_target_token),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec07f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]]=1\n",
    "    encoder_input_data[i,t+1:,input_token_index[' ']]=1\n",
    "    for t,char in enumerate(target_text):\n",
    "        if t>0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]]=1\n",
    "            \n",
    "        decoder_input_data[i,t+1:,target_token_index[' ']]=1\n",
    "        decoder_target_data[i,t:,target_token_index[' ']]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889d54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 53)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8aa8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "##model building\n",
    "\n",
    "encoder_inputs=Input(shape=(None,num_encoder_token))\n",
    "encoder=LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs,state_h,state_c=encoder(encoder_inputs)\n",
    "\n",
    "encoder_states=[state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6f634f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm')>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72b8b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_target_token))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_target_token, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15bacd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_5635]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6484\\3895163286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_train_function_5635]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index=dict((i,char) for char,i in input_token_index.items())\n",
    "reverse_target_char_index=dict((i,char) for char,i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f96b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "   \n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_target_token))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_target_token))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3211d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    input_seq=encoder_input_data[i: i+1]\n",
    "    decoded_sentence=decode_sequence(input_seq)\n",
    "    print(\"decoded_sentence\",decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ce62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sequence(encoder_input_data[2: 2+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65147de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7354a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(encoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307a245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
